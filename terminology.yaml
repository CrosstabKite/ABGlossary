
- title: 'Itâ€™s All A/Bout Testing: The Netflix Experimentation Platform'
  link: https://netflixtechblog.com/its-all-a-bout-testing-the-netflix-experimentation-platform-4e1ca458c15#annotations:pRwJrnugEeucIWdt9l-iJw
  orgs: Netflix
  authors: Steve Urban, Rangarajan Sreenivasan, Vineet Kannan
  terms:
    A/B test: an experiment with a control group and one or more experimental groups
    control group:
    experimental group:
    cell: a group of users
    treatment:
    default cell: the group of users that receives the control treatment, which is the
      same experience as all Netflix users not in the test.
    metric: outcomes of importance, typically streaming hours and retention
    allocation: how users are assigned to a test
    batch allocation:
    real-time allocation:
    stratified sampling:

- title: Improving Experimentation Efficiency at Netflix with Meta Analysis and Optimal Stopping
  link: https://netflixtechblog.com/improving-experimentation-efficiency-at-netflix-with-meta-analysis-and-optimal-stopping-d8ec290ae5be
  orgs: Netflix
  authors: Gang Su, Ian Yohai
  terms:
    power analysis:
    seasonality:
    novelty effect:
    treatment effect:
    HARKing:
    p-hacking:
    fixed effect model:
    random effect model:
    heterogeneous treatment effects:
    sequential triangular testing:
    group sequential testing:
    

- title: Statistics For Experimenters, 2nd edition
  link: https://statisticsforexperimenters.net/
  orgs:
  authors: George E.P. Box, J. Stuart Hunter, William G. Hunter
  terms:
    factor: controllable input variable
    level: a value of a factor. If the factor were font color, the levels might be blue
      and black.
    response: output variable
    error: "variability not explained by known influences". Also, "the fluctuation that
      occurs from one repetition to another". AKA 'experimental error', 'experimental
      variation'. 
    run: "an experimental run has been performed when an apparatus has been set up and
      allowed to function under a specific set of experimental conditions."
    block: a portion of experimental material expected to be more homogeneous than the
      aggregate. 
    blocking: comparisons within blocks have greater precision because between-block
      variability is eliminated. For example, testing shoe materials by asking each
      person to wear the new shoe on either their right or left foot, randomly.
    randomization: force unknown discrepancies between treatments to contribute
      homogeneously to the errors of each. This should be done after 'known' sources of
      discrepancy are removed by holding them constant or blocking.
    factorial design: conduct experiment runs in all possible combinations of levels
      across multiple factors.
  
- title: "Experimentation at Tubi"
  link: https://code.tubitv.com/experimentation-at-tubi-82f35afe2732
  orgs: Tubi
  authors: Change She
  terms:
    experiment engine:
    namespace: represents "a group of mutually exclusive experiments"
    assignment: mapping experiment targets to segments, done by a namespace
    targets: '"e.g. devices, users, IPs, etc"'
    segment: '"a group of experimental targets, allocated to at most one experiment"'
    allocation: mapping of segments to experiments
    treatment group:
    phase: stage of an experiment. Different phases "reserve differing amounts of
      segments".
    condition: Logic that refines segments, e.g. "only new users".
    start date:
    end date:
    override: '"inclusion of development and test devices in particular experiments
      and treatment groups"'
    graduate: progression of an experiment to the next phase
    exposure: the event where a target is impacted by a namespace, experiment, and
      treatment group.
    metric: 
    Northstar metrics: "A small subset of metrics that are closest to top-level company
      KPIs"
    do-no-harm criterion: "an experiment that harms any Northstar metric cannot be
      graduated without...a...review process."
    uneven split: a large difference between the number of users in each group
    
- title: Trustworthy Online Controlled Experimentation
  link: experimentguide.com
  orgs: Microsoft, Amazon, Google, LinkedIn
  authors: Ron Kohavi, Diane Tang, Ya Xu
  terms:
    online controlled experiment: "users are split between variants in a persistent
      manner"
    instrumentation: monitoring and logging of a system
    metric:
    overall evaluation criterion (OEC): "A quantitative measure of the experiment's
      objective...For example...active days per user..." May be a combination of
      metrics. Also known as the response or the dependent variable.
    parameter: "A controllable experimental variable that is thought to
      influence...metrics of interest."
    value: A specific value assigned to a variable parameter. If the parameter is font
      color, for example, then a value might be 'blue'.
    variant: the experience being tested, created by assigning values to all the
      parameters. In an A/B test, A and B represent the two variants. Similarly,
      'control' and 'treatment' are variants.
    control: a special variant, namely the "existing version on which to run the
      comparison."
    treatment:
    unit: "e.g., users or pages"
    randomization (unit): application of a pseudo-random process to map units to
      variants. For online audiences, it is common to use 'users' as the randomization
      unit, but it is also possible to randomize by pages, sessions, or user-day.
    
    


  